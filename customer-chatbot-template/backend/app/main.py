"""
FastAPI Application with ChatKit Server

This is the main entry point for the customer chatbot backend.
It sets up the FastAPI app, ChatKit server, and API endpoints.

ARCHITECTURE:
- KnowledgeAssistantServer: ChatKit server implementation that handles chat protocol
- FastAPI app: REST API endpoints for documents, citations, and health checks
- Agent integration: Uses OpenAI Agents SDK with File Search for grounded responses

CUSTOMIZATION POINTS:
1. config.py - All configuration values (model, instructions, etc.)
2. assistant_agent.py - Agent behavior and tools
3. documents.py - Document metadata (auto-generated by setup script)
4. memory_store.py - Replace with database store for production

API ENDPOINTS:
- POST /knowledge/chatkit - ChatKit protocol endpoint (streaming SSE)
- GET /knowledge/documents - List all documents with metadata
- GET /knowledge/documents/{id}/file - Serve document files for preview
- GET /knowledge/threads/{id}/citations - Get citations from latest response
- GET /knowledge/health - Health check endpoint
"""
from __future__ import annotations

import mimetypes
import re
from itertools import chain
from pathlib import Path
from typing import Any, AsyncIterator, Iterable

from agents import Agent, RunConfig, Runner
from agents.model_settings import ModelSettings
from chatkit.agents import AgentContext, stream_agent_response
from chatkit.server import ChatKitServer, StreamingResult
from chatkit.types import (
    Annotation,
    AssistantMessageContent,
    AssistantMessageItem,
    Attachment,
    ClientToolCallItem,
    ThreadItem,
    ThreadMetadata,
    ThreadStreamEvent,
    UserMessageItem,
)
from fastapi import Depends, FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, Response, StreamingResponse
from openai.types.responses import ResponseInputContentParam
from starlette.responses import JSONResponse

from .assistant_agent import assistant_agent
from .config import ASSISTANT_TEMPERATURE, CORS_ORIGINS, DATA_DIR
from .documents import (
    DOCUMENTS,
    DOCUMENTS_BY_FILENAME,
    DOCUMENTS_BY_ID,
    DOCUMENTS_BY_SLUG,
    DOCUMENTS_BY_STEM,
    DocumentMetadata,
    as_dicts,
)
from .memory_store import MemoryStore


# ==============================================================================
# UTILITY FUNCTIONS
# ==============================================================================

def _normalise_filename(value: str) -> str:
    """Extract and normalize filename for matching."""
    return Path(value).name.strip().lower()


def _slug(value: str | None) -> str:
    """Convert string to alphanumeric slug for fuzzy matching."""
    if not value:
        return ""
    return "".join(ch for ch in value.lower() if ch.isalnum())


def _user_message_text(item: UserMessageItem) -> str:
    """
    Extract text content from a user message item.

    ChatKit messages can contain multiple content parts. This combines
    all text parts into a single string.
    """
    parts: list[str] = []
    for part in item.content:
        text = getattr(part, "text", None)
        if text:
            parts.append(text)
    return " ".join(parts).strip()


def _resolve_document(annotation: Annotation) -> DocumentMetadata | None:
    """
    Resolve a citation annotation to a document from our metadata registry.

    The AI assistant returns annotations with filenames that may not exactly
    match our document registry. This function tries multiple strategies:
    1. Exact filename match
    2. Stem match (filename without extension)
    3. Slug match (fuzzy alphanumeric matching)
    4. Title/description matching

    Args:
        annotation: Annotation from AI assistant response

    Returns:
        DocumentMetadata if matched, None otherwise
    """
    source = getattr(annotation, "source", None)
    if not source or getattr(source, "type", None) != "file":
        return None

    # Try matching by filename
    filename = getattr(source, "filename", None)
    if filename:
        normalised = _normalise_filename(filename)
        match = DOCUMENTS_BY_FILENAME.get(normalised)
        if match:
            return match
        stem_match = DOCUMENTS_BY_STEM.get(Path(normalised).stem.lower())
        if stem_match:
            return stem_match
        slug_match = DOCUMENTS_BY_SLUG.get(_slug(normalised))
        if slug_match:
            return slug_match

    # Try matching by title
    title = getattr(source, "title", None)
    if title:
        candidate = DOCUMENTS_BY_SLUG.get(_slug(title))
        if candidate:
            return candidate

    # Try matching by description
    description = getattr(source, "description", None)
    if description:
        candidate = DOCUMENTS_BY_SLUG.get(_slug(description))
        if candidate:
            return candidate

    return None


# CUSTOMIZE THIS REGEX: Update to match your document naming patterns
# Default pattern matches: 01_filename.pdf, 02_document.html, etc.
_FILENAME_REGEX = re.compile(r"(\d+_[a-z0-9_\-]+\.(?:pdf|html|txt|docx))", re.IGNORECASE)


def _documents_from_text(text: str) -> Iterable[DocumentMetadata]:
    """
    Extract document references from plain text using regex.

    This is a fallback for when the AI doesn't provide proper annotations.
    It looks for filenames mentioned in the response text and matches them
    to documents in our registry.

    CUSTOMIZATION: Update _FILENAME_REGEX to match your naming convention

    Args:
        text: Text to search for document references

    Returns:
        Iterator of matched DocumentMetadata objects
    """
    if not text:
        return []
    matches = {match.lower() for match in _FILENAME_REGEX.findall(text)}
    if not matches:
        return []
    results: list[DocumentMetadata] = []
    for filename in matches:
        doc = DOCUMENTS_BY_FILENAME.get(filename)
        if doc and doc not in results:
            results.append(doc)
    return results


def _is_tool_completion_item(item: Any) -> bool:
    """Check if an item is a tool completion (vs user message)."""
    return isinstance(item, ClientToolCallItem)


# ==============================================================================
# CHATKIT SERVER IMPLEMENTATION
# ==============================================================================

class KnowledgeAssistantServer(ChatKitServer[dict[str, Any]]):
    """
    ChatKit server that integrates OpenAI Agents SDK with ChatKit protocol.

    This server:
    1. Receives user messages via ChatKit protocol
    2. Runs them through the AI assistant agent
    3. Streams responses back to the frontend
    4. Extracts and returns citations for UI highlighting

    The server uses a Store implementation (MemoryStore by default) to persist
    conversation threads and messages.

    PRODUCTION TODO:
    - Replace MemoryStore with database-backed store
    - Add authentication/authorization
    - Add rate limiting
    - Add logging and monitoring
    """

    def __init__(self, agent: Agent[AgentContext]) -> None:
        """
        Initialize the ChatKit server.

        Args:
            agent: The AI assistant agent from assistant_agent.py
        """
        self.store = MemoryStore()
        super().__init__(self.store)
        self.assistant = agent

    async def respond(
        self,
        thread: ThreadMetadata,
        item: ThreadItem | None,
        context: dict[str, Any],
    ) -> AsyncIterator[ThreadStreamEvent]:
        """
        Generate a response to a user message.

        This is the core of the ChatKit server. It:
        1. Validates the incoming item is a user message
        2. Extracts the text content
        3. Creates agent context with thread and store
        4. Runs the agent with streaming enabled
        5. Streams events back to the client

        Args:
            thread: Metadata for the current conversation thread
            item: The latest thread item (usually a user message)
            context: Request context (contains FastAPI Request object)

        Yields:
            ThreadStreamEvent objects (text deltas, tool calls, etc.)
        """
        # Ignore empty items
        if item is None:
            return

        # Ignore tool completion items (we only respond to user messages)
        if _is_tool_completion_item(item):
            return

        # Only respond to user messages
        if not isinstance(item, UserMessageItem):
            return

        # Extract text from the message
        message_text = _user_message_text(item)
        if not message_text:
            return

        # Create agent context with thread and store access
        agent_context = AgentContext(
            thread=thread,
            store=self.store,
            request_context=context,
        )

        # Run the agent with streaming
        # Temperature is configured in config.py
        result = Runner.run_streamed(
            self.assistant,
            message_text,
            context=agent_context,
            run_config=RunConfig(model_settings=ModelSettings(temperature=ASSISTANT_TEMPERATURE)),
        )

        # Stream response events to the client
        async for event in stream_agent_response(agent_context, result):
            yield event

    async def to_message_content(self, input: Attachment) -> ResponseInputContentParam:
        """
        Convert uploaded attachments to message content.

        NOT IMPLEMENTED in this template for security reasons.

        PRODUCTION TODO:
        - Implement file upload validation
        - Add virus scanning
        - Store files securely (S3, Azure Blob, etc.)
        - Return appropriate content representation
        """
        raise RuntimeError(
            "File attachments are not supported in this template. "
            "Implement to_message_content() with proper security measures for production."
        )

    async def latest_citations(
        self, thread_id: str, context: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """
        Extract citations from the latest assistant response in a thread.

        This method:
        1. Loads recent thread items
        2. Finds the most recent assistant message
        3. Extracts citations from annotations or text
        4. Returns structured citation data for the frontend

        Args:
            thread_id: ID of the conversation thread
            context: Request context

        Returns:
            List of citation dictionaries with document metadata
        """
        # Load recent items (last 50, newest first)
        items = await self.store.load_thread_items(
            thread_id,
            after=None,
            limit=50,
            order="desc",
            context=context,
        )

        # Find the first assistant message with citations
        for item in items.data:
            if isinstance(item, AssistantMessageItem):
                citations = list(self._extract_citations(item))
                if citations:
                    return citations
        return []

    def _extract_citations(self, item: AssistantMessageItem) -> Iterable[dict[str, Any]]:
        """
        Extract all citations from an assistant message.

        Tries two strategies:
        1. Parse annotations (structured citations from AI)
        2. Regex search for filenames in text (fallback)

        Args:
            item: Assistant message to extract citations from

        Yields:
            Citation dictionaries with document_id, filename, title, etc.
        """
        found = False

        # Strategy 1: Extract from annotations (preferred)
        for content in item.content:
            if not isinstance(content, AssistantMessageContent):
                continue
            for annotation in content.annotations:
                document = _resolve_document(annotation)
                if not document:
                    continue
                found = True
                yield {
                    "document_id": document.id,
                    "filename": document.filename,
                    "title": document.title,
                    "description": document.description,
                    "annotation_index": annotation.index,
                }

        # Strategy 2: Fallback to regex search if no annotations found
        if not found:
            texts = chain.from_iterable(
                content.text.splitlines()
                for content in item.content
                if isinstance(content, AssistantMessageContent)
            )
            for line in texts:
                for document in _documents_from_text(line):
                    yield {
                        "document_id": document.id,
                        "filename": document.filename,
                        "title": document.title,
                        "description": document.description,
                        "annotation_index": None,
                    }


# ==============================================================================
# FASTAPI APPLICATION
# ==============================================================================

# Initialize the ChatKit server with our assistant agent
knowledge_server = KnowledgeAssistantServer(agent=assistant_agent)

# Create FastAPI app
app = FastAPI(
    title="Customer Knowledge Assistant API",
    description="ChatKit-powered knowledge assistant with document retrieval",
    version="1.0.0",
)

# CORS middleware - CUSTOMIZE for production (restrict to your frontend domain)
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def get_server() -> KnowledgeAssistantServer:
    """Dependency injection for ChatKit server."""
    return knowledge_server


# ==============================================================================
# API ENDPOINTS
# ==============================================================================

@app.post("/knowledge/chatkit")
async def chatkit_endpoint(
    request: Request, server: KnowledgeAssistantServer = Depends(get_server)
) -> Response:
    """
    ChatKit protocol endpoint.

    This endpoint handles the bidirectional ChatKit protocol:
    - Client sends chat actions (create thread, send message, etc.)
    - Server processes and returns responses
    - Supports streaming (Server-Sent Events) for real-time responses

    The ChatKit library handles all protocol details internally.
    """
    payload = await request.body()
    result = await server.process(payload, {"request": request})

    # Return streaming response for real-time updates
    if isinstance(result, StreamingResult):
        return StreamingResponse(result, media_type="text/event-stream")

    # Return JSON response for non-streaming operations
    if hasattr(result, "json"):
        return Response(content=result.json, media_type="application/json")
    return JSONResponse(result)


@app.get("/knowledge/documents")
async def list_documents() -> dict[str, Any]:
    """
    List all documents in the knowledge base.

    Returns document metadata for display in the UI.
    The actual document content is stored in OpenAI Vector Store.

    Returns:
        {"documents": [{"id": "...", "filename": "...", "title": "...", ...}]}
    """
    return {"documents": as_dicts(DOCUMENTS)}


@app.get("/knowledge/documents/{document_id}/file")
async def document_file(document_id: str) -> FileResponse:
    """
    Serve a document file for preview.

    Documents are served from the DATA_DIR (backend/data/).
    The frontend displays these in an iframe for user preview.

    Args:
        document_id: Document ID from documents.py

    Returns:
        File response with appropriate MIME type

    Raises:
        HTTPException: 404 if document not found or file missing
    """
    document = DOCUMENTS_BY_ID.get(document_id)
    if document is None:
        raise HTTPException(status_code=404, detail="Document not found")

    file_path = DATA_DIR / document.filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="File not available")

    # Guess MIME type from file extension
    media_type, _ = mimetypes.guess_type(str(file_path))

    # Set inline disposition so browsers display (not download) the file
    headers = {"Content-Disposition": f'inline; filename="{document.filename}"'}

    return FileResponse(
        file_path,
        media_type=media_type or "application/octet-stream",
        headers=headers,
    )


@app.get("/knowledge/threads/{thread_id}/citations")
async def thread_citations(
    thread_id: str,
    request: Request,
    server: KnowledgeAssistantServer = Depends(get_server),
) -> dict[str, Any]:
    """
    Get citations from the latest response in a thread.

    The frontend calls this after each assistant response to:
    1. Highlight cited documents in the UI
    2. Show which documents were used for the response

    Args:
        thread_id: Conversation thread ID
        request: FastAPI request object
        server: ChatKit server instance

    Returns:
        {
            "documentIds": ["id1", "id2", ...],  # Unique cited document IDs
            "citations": [                        # Full citation details
                {
                    "document_id": "...",
                    "filename": "...",
                    "title": "...",
                    "description": "...",
                    "annotation_index": 0
                },
                ...
            ]
        }

    Raises:
        HTTPException: 404 if thread not found or error extracting citations
    """
    context = {"request": request}
    try:
        citations = await server.latest_citations(thread_id, context=context)
    except Exception as exc:  # noqa: BLE001
        raise HTTPException(status_code=404, detail=str(exc)) from exc

    # Extract unique document IDs for UI highlighting
    document_ids = sorted({citation["document_id"] for citation in citations})

    return {"documentIds": document_ids, "citations": citations}


@app.get("/knowledge/health")
async def health_check() -> dict[str, str]:
    """
    Health check endpoint for monitoring and load balancers.

    Returns:
        {"status": "healthy"}
    """
    return {"status": "healthy"}


# ==============================================================================
# APPLICATION ENTRY POINT
# ==============================================================================

if __name__ == "__main__":
    import uvicorn
    from .config import SERVER_HOST, SERVER_PORT, LOG_LEVEL

    uvicorn.run(
        "app.main:app",
        host=SERVER_HOST,
        port=SERVER_PORT,
        reload=True,  # Enable auto-reload for development
        log_level=LOG_LEVEL.lower(),
    )
